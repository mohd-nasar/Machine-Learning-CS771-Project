{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS771 HomeWork Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imporing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignoring Warning for cleaner look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ye bas final ke liye run karna kuch erro find karna ho  to run mat karna \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50 for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "model.fc = torch.nn.Identity()  # Remove last layer for feature extraction\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GPU if avaliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation (resize, normalize, etc.)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function (to be used if using nn classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        confidence = 1.0 - self.smoothing\n",
    "        smooth_label = self.smoothing / pred.size(1)\n",
    "        one_hot = torch.zeros_like(pred).scatter(1, target.unsqueeze(1), 1)\n",
    "        log_probs = pred.log_softmax(dim=-1)\n",
    "        return -(confidence * one_hot + smooth_label).mul(log_probs).sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data = torch.load(path, weights_only=False)\n",
    "    images = data.get('data')\n",
    "    if images is None:\n",
    "        raise ValueError(f\"'data' key is missing or None in file: {path}\")\n",
    "\n",
    "    labels = data.get('targets')\n",
    "    if labels is None:\n",
    "        labels = None\n",
    "\n",
    "    features = torch.tensor(images / 255.0, dtype=torch.float32).contiguous()\n",
    "    if labels is not None:\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction function\n",
    "def extract_features(images):\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for img in images:\n",
    "            img_tensor = transform(img).unsqueeze(0)\n",
    "            feat = model(img_tensor).view(1, -1)  # Flatten to 1D\n",
    "            features.append(feat.numpy())\n",
    "    return np.concatenate(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "heldout_features = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and store features only once for each heldout dataset\n",
    "def get_or_extract_features(dataset_name, dataset_data):\n",
    "    if dataset_name not in heldout_features:\n",
    "        heldout_features[dataset_name] = extract_features(dataset_data)\n",
    "    return heldout_features[dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Class Protoype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class prototypes\n",
    "def compute_prototypes(features, labels):\n",
    "    prototypes = {}\n",
    "    for label in np.unique(labels):\n",
    "        prototypes[label] = features[labels == label].mean(axis=0)\n",
    "    return prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrastive alignment\n",
    "def prototype_contrastive_alignment(prev_prototypes, curr_prototypes, alpha=0.5):\n",
    "    aligned_prototypes = {}\n",
    "    for cls in curr_prototypes.keys():\n",
    "        if cls in prev_prototypes:\n",
    "            aligned_prototypes[cls] = alpha * prev_prototypes[cls] + (1 - alpha) * curr_prototypes[cls]\n",
    "        else:\n",
    "            aligned_prototypes[cls] = curr_prototypes[cls]\n",
    "    return aligned_prototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction using Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with Cosine Similarity\n",
    "def cosine_pseudo_labels(features, prototypes):\n",
    "    predictions, confidences = [], []\n",
    "\n",
    "    # Prepare prototypes as a matrix for vectorized computation\n",
    "    proto_matrix = np.array(list(prototypes.values()))\n",
    "    proto_labels = list(prototypes.keys())\n",
    "\n",
    "    # Normalize prototypes for cosine similarity\n",
    "    proto_norms = np.linalg.norm(proto_matrix, axis=1, keepdims=True)\n",
    "    normalized_prototypes = proto_matrix / proto_norms\n",
    "\n",
    "    for feature in features:\n",
    "        # Normalize the feature\n",
    "        feature_norm = np.linalg.norm(feature)\n",
    "        normalized_feature = feature / feature_norm\n",
    "\n",
    "        # Compute cosine similarity with all prototypes\n",
    "        similarities = normalized_prototypes @ normalized_feature\n",
    "\n",
    "        # Get the top class with highest similarity\n",
    "        sorted_indices = np.argsort(similarities)[::-1]\n",
    "        top_class = proto_labels[sorted_indices[0]]\n",
    "        top_sim = similarities[sorted_indices[0]]\n",
    "        second_sim = similarities[sorted_indices[1]]\n",
    "\n",
    "        # Confidence is the ratio of top two similarities\n",
    "        confidence = second_sim / top_sim if top_sim != 0 else 0\n",
    "\n",
    "        predictions.append(top_class)\n",
    "        confidences.append(confidence)\n",
    "\n",
    "    return np.array(predictions), np.array(confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "performance_matrix = np.zeros((20, 20))\n",
    "prev_prototypes = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn Classifier (to be used if cuda is avaliable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the f1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = torch.load('../dataset/dataset/part_one_dataset/train_data/1_train_data.tar.pth')\n",
    "train1_images = train1['data']\n",
    "train1_labels = train1['targets']\n",
    "\n",
    "train1_features = extract_features(train1_images)\n",
    "prototype1 = compute_prototypes(train1_features, train1_labels)\n",
    "\n",
    "prev_prototypes = prototype1\n",
    "\n",
    "\n",
    "test1 = torch.load('../dataset/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth')\n",
    "test1_images = test1['data']\n",
    "test1_labels = test1['targets']\n",
    "\n",
    "test1_features = get_or_extract_features(\"D1\", test1_images)\n",
    "predictions, _ = cosine_pseudo_labels(test1_features, prototype1)\n",
    "accuracy = accuracy_score(test1_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_matrix[0][0] = accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7992"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training , Predicting and building Models for Task-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7776\n",
      "0.7892\n",
      "0.77\n",
      "0.7884\n",
      "0.7784\n",
      "0.7656\n",
      "0.7792\n",
      "0.774\n",
      "0.7764\n",
      "0.7596\n",
      "0.7736\n",
      "0.7688\n",
      "0.7708\n",
      "0.7708\n",
      "0.754\n",
      "0.7676\n",
      "0.7612\n",
      "0.7676\n",
      "0.7708\n",
      "0.7628\n",
      "0.754\n",
      "0.7688\n",
      "0.7584\n",
      "0.7652\n",
      "0.7692\n",
      "0.758\n",
      "0.7556\n",
      "0.748\n",
      "0.76\n",
      "0.76\n",
      "0.7628\n",
      "0.7636\n",
      "0.7536\n",
      "0.7524\n",
      "0.7532\n",
      "0.7476\n",
      "0.7616\n",
      "0.7604\n",
      "0.7604\n",
      "0.7592\n",
      "0.7548\n",
      "0.7492\n",
      "0.752\n",
      "0.7344\n",
      "0.7432\n",
      "0.7588\n",
      "0.756\n",
      "0.7596\n",
      "0.7556\n",
      "0.7528\n",
      "0.7488\n",
      "0.75\n",
      "0.732\n",
      "0.7688\n"
     ]
    }
   ],
   "source": [
    "# Update loop for D2 to D10\n",
    "for i in range(2, 11):\n",
    "    # Load and extract features\n",
    "    train = torch.load(f'../dataset/dataset/part_one_dataset/train_data/{i}_train_data.tar.pth')\n",
    "    train_images = train['data']\n",
    "    features = extract_features(train_images)\n",
    "\n",
    "    # Predict pseudo-labels using cosine similarity\n",
    "    pseudo_labels, confidences = cosine_pseudo_labels(features, prev_prototypes)\n",
    "\n",
    "    # Filter by confidence threshold\n",
    "    reliable_indices = confidences > 0.5  # Confidence threshold\n",
    "    reliable_features = features[reliable_indices]\n",
    "    reliable_labels = pseudo_labels[reliable_indices]\n",
    "\n",
    "    # Compute and align prototypes\n",
    "    prototypes = compute_prototypes(reliable_features, reliable_labels)\n",
    "    prototypes = prototype_contrastive_alignment(prev_prototypes, prototypes)\n",
    "\n",
    "    # Evaluate on held-out datasets\n",
    "    for j in range(1, i + 1):\n",
    "        \n",
    "        test = torch.load(f'../dataset/dataset/part_one_dataset/eval_data/{j}_eval_data.tar.pth')\n",
    "\n",
    "        test_images = test['data']\n",
    "        test_labels = test['targets']\n",
    "        test_features = get_or_extract_features(f'D{j}', test_images)\n",
    "\n",
    "        predictions, _ = cosine_pseudo_labels(test_features, prototypes)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        performance_matrix[i-1, j-1] = accuracy*100\n",
    "\n",
    "    prev_prototypes = prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Predicting and Building Models for Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7156\n",
      "0.7252\n",
      "0.7372\n",
      "0.7352\n",
      "0.7192\n",
      "0.7264\n",
      "0.7232\n",
      "0.726\n",
      "0.7044\n",
      "0.7436\n"
     ]
    }
   ],
   "source": [
    "# Update loop for D2 to D10\n",
    "for i in range(11, 21):\n",
    "    # Load and extract features\n",
    "    train = torch.load(f'../dataset/dataset/part_two_dataset/train_data/{i-10}_train_data.tar.pth')\n",
    "    train_images = train['data']\n",
    "    features = extract_features(train_images)\n",
    "\n",
    "    # Predict pseudo-labels using cosine similarity\n",
    "    pseudo_labels, confidences = cosine_pseudo_labels(features, prev_prototypes)\n",
    "\n",
    "    # Filter by confidence threshold\n",
    "    reliable_indices = confidences > 0.5  # Confidence threshold\n",
    "    reliable_features = features[reliable_indices]\n",
    "    reliable_labels = pseudo_labels[reliable_indices]\n",
    "\n",
    "    # Compute and align prototypes\n",
    "    prototypes = compute_prototypes(reliable_features, reliable_labels)\n",
    "    prototypes = prototype_contrastive_alignment(prev_prototypes, prototypes)\n",
    "\n",
    "    # Evaluate on held-out datasets\n",
    "    for j in range(1, i + 1):\n",
    "\n",
    "        if j > 10:\n",
    "            test = torch.load(f'../dataset/dataset/part_two_dataset/eval_data/{j-10}_eval_data.tar.pth')\n",
    "        else:\n",
    "            test = torch.load(f'../dataset/dataset/part_one_dataset/eval_data/{j}_eval_data.tar.pth')\n",
    "        \n",
    "\n",
    "        test_images = test['data']\n",
    "        test_labels = test['targets']\n",
    "        test_features = get_or_extract_features(f'D{j}', test_images)\n",
    "\n",
    "        predictions, _ = cosine_pseudo_labels(test_features, prototypes)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        performance_matrix[i-1, j-1] = accuracy*100\n",
    "\n",
    "    prev_prototypes = prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(performance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Task2 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracy Matrix\n",
    "sns.heatmap(performance_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Accuracy Matrix\")\n",
    "plt.xlabel(\"Heldout Dataset\")\n",
    "plt.ylabel(\"Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert performance matrix into a DataFrame for better formatting\n",
    "df = pd.DataFrame(performance_matrix, \n",
    "                  index=[f\"Model {i+1}\" for i in range(performance_matrix.shape[0])], \n",
    "                  columns=[f\"D{j}\" for j in range(1, performance_matrix.shape[1]+1)])\n",
    "\n",
    "# Plot table\n",
    "fig, ax = plt.subplots(figsize=(12, 6))  # Adjust size as needed\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "table = ax.table(cellText=df.round(2).values,  # Round values to 2 decimal places\n",
    "                 rowLabels=df.index, \n",
    "                 colLabels=df.columns, \n",
    "                 cellLoc=\"center\", \n",
    "                 loc=\"center\",\n",
    "                 colColours=[\"#f5f5f5\"] * len(df.columns))  # Optional: light column background color\n",
    "\n",
    "# Adjust font size for readability\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "\n",
    "plt.title(\"Accuracy Matrix (Tabular View)\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
